{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transfer Learning- Model is trained here on imagenet dataset and we transfer the learning to predict on the different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading images and labels\n",
    "(train_ds, train_labels), (test_ds, test_labels) = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:70%]\", \"train[:30%]\"], ## Train test split\n",
    "    batch_size=-1,\n",
    "    as_supervised=True,  # Include labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([442, 1024, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.image.resize(train_ds, (150, 150))\n",
    "test_ds = tf.image.resize(test_ds, (150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(150, 150, 3), dtype=float32, numpy=\n",
       "array([[[105.833336, 132.12001 ,  35.522312],\n",
       "        [115.6264  , 138.69307 ,  42.374935],\n",
       "        [ 99.71022 , 125.11689 ,  30.989334],\n",
       "        ...,\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ]],\n",
       "\n",
       "       [[123.5656  , 141.052   ,  37.0528  ],\n",
       "        [133.22081 , 149.3816  ,  58.62    ],\n",
       "        [100.989334, 129.396   ,  40.490665],\n",
       "        ...,\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ]],\n",
       "\n",
       "       [[126.98178 , 139.612   ,  27.463554],\n",
       "        [137.352   , 152.64134 ,  63.65867 ],\n",
       "        [115.04001 , 142.34001 ,  51.902225],\n",
       "        ...,\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        ...,\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ]],\n",
       "\n",
       "       [[  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        ...,\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ]],\n",
       "\n",
       "       [[  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        ...,\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ],\n",
       "        [  0.      ,   0.      ,   0.      ]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2569,), dtype=int64, numpy=array([2, 3, 3, ..., 0, 2, 0], dtype=int64)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels, num_classes=5)\n",
    "test_labels = to_categorical(test_labels, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained VGG16 Image Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([150, 150, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2569, 150, 150, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading VGG16 model\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=train_ds[0].shape)\n",
    "#base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(150,150,3))\n",
    "\n",
    "#both are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## will not train base mode\n",
    "base_model.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing input\n",
    "train_ds = preprocess_input(train_ds) \n",
    "test_ds = preprocess_input(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add our layers on top of this model\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "flatten_layer = layers.Flatten()\n",
    "dense_layer_1 = layers.Dense(50, activation='relu')\n",
    "dense_layer_2 = layers.Dense(20, activation='relu')\n",
    "prediction_layer = layers.Dense(5, activation='softmax')\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,                     #added VGG16 base model\n",
    "    flatten_layer,\n",
    "    dense_layer_1,\n",
    "    dense_layer_2,\n",
    "    prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)  #avoid overfitting and if the model is not improving, it will stop at that level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "65/65 [==============================] - 246s 4s/step - loss: 1.8143 - accuracy: 0.5027 - val_loss: 1.1066 - val_accuracy: 0.6304\n",
      "Epoch 2/50\n",
      "65/65 [==============================] - 228s 4s/step - loss: 0.7416 - accuracy: 0.7518 - val_loss: 0.9333 - val_accuracy: 0.7004\n",
      "Epoch 3/50\n",
      "65/65 [==============================] - 225s 3s/step - loss: 0.5066 - accuracy: 0.8161 - val_loss: 0.9262 - val_accuracy: 0.7121\n",
      "Epoch 4/50\n",
      "65/65 [==============================] - 223s 3s/step - loss: 0.3068 - accuracy: 0.9002 - val_loss: 1.0042 - val_accuracy: 0.6984\n",
      "Epoch 5/50\n",
      "65/65 [==============================] - 221s 3s/step - loss: 0.2080 - accuracy: 0.9358 - val_loss: 1.0497 - val_accuracy: 0.6946\n",
      "Epoch 6/50\n",
      "65/65 [==============================] - 221s 3s/step - loss: 0.1536 - accuracy: 0.9518 - val_loss: 1.0430 - val_accuracy: 0.6965\n",
      "Epoch 7/50\n",
      "65/65 [==============================] - 221s 3s/step - loss: 0.1200 - accuracy: 0.9606 - val_loss: 1.1266 - val_accuracy: 0.6965\n",
      "Epoch 8/50\n",
      "65/65 [==============================] - 222s 3s/step - loss: 0.0875 - accuracy: 0.9737 - val_loss: 1.2032 - val_accuracy: 0.7082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df219446a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, train_labels, epochs=50, validation_split=0.2, batch_size=32, callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "65/65 [==============================] - 20s 273ms/step - loss: 1.5272 - accuracy: 0.2876 - val_loss: 1.4670 - val_accuracy: 0.3541\n",
      "Epoch 2/50\n",
      "65/65 [==============================] - 15s 233ms/step - loss: 1.3720 - accuracy: 0.3781 - val_loss: 1.2481 - val_accuracy: 0.4572\n",
      "Epoch 3/50\n",
      "65/65 [==============================] - 16s 245ms/step - loss: 1.2278 - accuracy: 0.4710 - val_loss: 1.2123 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "65/65 [==============================] - 15s 233ms/step - loss: 1.1650 - accuracy: 0.5217 - val_loss: 1.2014 - val_accuracy: 0.4689\n",
      "Epoch 5/50\n",
      "65/65 [==============================] - 16s 241ms/step - loss: 1.0869 - accuracy: 0.5421 - val_loss: 1.2124 - val_accuracy: 0.4883\n",
      "Epoch 6/50\n",
      "65/65 [==============================] - 16s 250ms/step - loss: 1.0203 - accuracy: 0.5830 - val_loss: 1.1304 - val_accuracy: 0.5389\n",
      "Epoch 7/50\n",
      "65/65 [==============================] - 14s 217ms/step - loss: 0.9392 - accuracy: 0.6273 - val_loss: 1.2177 - val_accuracy: 0.5681\n",
      "Epoch 8/50\n",
      "65/65 [==============================] - 15s 238ms/step - loss: 0.8782 - accuracy: 0.6477 - val_loss: 1.2196 - val_accuracy: 0.5214\n",
      "Epoch 9/50\n",
      "65/65 [==============================] - 14s 221ms/step - loss: 0.8335 - accuracy: 0.6813 - val_loss: 1.1805 - val_accuracy: 0.5486\n",
      "Epoch 10/50\n",
      "65/65 [==============================] - 14s 222ms/step - loss: 0.7592 - accuracy: 0.6964 - val_loss: 1.1792 - val_accuracy: 0.5506\n",
      "Epoch 11/50\n",
      "65/65 [==============================] - 14s 218ms/step - loss: 0.6755 - accuracy: 0.7411 - val_loss: 1.3177 - val_accuracy: 0.5623\n",
      "Epoch 12/50\n",
      "65/65 [==============================] - 16s 246ms/step - loss: 0.6157 - accuracy: 0.7591 - val_loss: 1.3248 - val_accuracy: 0.5370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df22a7de20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "\n",
    "full_model = Sequential()\n",
    "full_model.add(Rescaling(1./255, input_shape=(150,150,3)))\n",
    "\n",
    "full_model.add(layers.Conv2D(16, kernel_size=10, activation='relu'))\n",
    "full_model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "full_model.add(layers.Conv2D(32, kernel_size=8, activation=\"relu\"))\n",
    "full_model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "full_model.add(layers.Conv2D(32, kernel_size=6, activation=\"relu\"))\n",
    "full_model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "full_model.add(layers.Flatten())\n",
    "full_model.add(layers.Dense(50, activation='relu'))\n",
    "full_model.add(layers.Dense(20, activation='relu'))\n",
    "full_model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "full_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
    "\n",
    "full_model.fit(train_ds, train_labels, epochs=50, validation_split=0.2, batch_size=32, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
